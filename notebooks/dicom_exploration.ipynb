{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "553d4ae8",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the required libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 15)\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")\n",
    "print(f\"  NumPy version: {np.__version__}\")\n",
    "print(f\"  Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858823a",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. üìÅ DICOM File Loading\n",
    "\n",
    "DICOM (Digital Imaging and Communications in Medicine) is the standard format for medical images like X-rays, CT scans, and MRIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our DICOM loader\n",
    "from ingestion import DICOMLoader, DICOMValidator, MetadataExtractor\n",
    "\n",
    "# Initialize the loader\n",
    "loader = DICOMLoader(\n",
    "    source_type=\"local\",\n",
    "    batch_size=100,\n",
    "    supported_modalities=[\"CT\", \"MR\", \"CR\", \"DX\"]  # Common imaging types\n",
    ")\n",
    "\n",
    "print(\"DICOMLoader Configuration:\")\n",
    "print(f\"  Source type: {loader.source_type}\")\n",
    "print(f\"  Batch size: {loader.batch_size}\")\n",
    "print(f\"  Supported modalities: {loader.supported_modalities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for sample DICOM files\n",
    "data_dir = Path.cwd().parent / \"data\" / \"dicom\"\n",
    "\n",
    "if data_dir.exists():\n",
    "    dcm_files = list(data_dir.rglob(\"*.dcm\"))\n",
    "    print(f\"Found {len(dcm_files)} DICOM files in {data_dir}\")\n",
    "    \n",
    "    if dcm_files:\n",
    "        # Load files\n",
    "        results = loader.load_directory(data_dir)\n",
    "        print(f\"\\nLoaded {len(results)} files successfully\")\n",
    "        \n",
    "        # Show statistics\n",
    "        stats = loader.get_statistics()\n",
    "        print(f\"\\nStatistics: {stats}\")\n",
    "else:\n",
    "    print(f\"No data directory found at {data_dir}\")\n",
    "    print(\"\\nTo test with real DICOM files:\")\n",
    "    print(\"1. Download sample files from pydicom or NIH datasets\")\n",
    "    print(\"2. Place them in data/dicom/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5c3c9",
   "metadata": {},
   "source": [
    "### Understanding DICOM Metadata\n",
    "\n",
    "DICOM files contain rich metadata about the patient, study, and image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0027cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key DICOM metadata fields\n",
    "metadata_info = {\n",
    "    \"Patient Information\": [\n",
    "        \"PatientID - Unique patient identifier\",\n",
    "        \"PatientName - Patient's name (PHI - must be anonymized!)\",\n",
    "        \"PatientBirthDate - Date of birth (PHI)\",\n",
    "        \"PatientSex - M/F/O\"\n",
    "    ],\n",
    "    \"Study Information\": [\n",
    "        \"StudyDate - Date of the imaging study\",\n",
    "        \"StudyDescription - Description of the study\",\n",
    "        \"Modality - CT, MR, CR (X-ray), DX (Digital X-ray)\",\n",
    "        \"BodyPartExamined - Chest, Head, etc.\"\n",
    "    ],\n",
    "    \"Image Information\": [\n",
    "        \"Rows - Image height in pixels\",\n",
    "        \"Columns - Image width in pixels\",\n",
    "        \"PixelSpacing - Physical size of pixels (mm)\",\n",
    "        \"WindowCenter/Width - Display settings\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, fields in metadata_info.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for field in fields:\n",
    "        print(f\"  ‚Ä¢ {field}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36760325",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. üîí Data Anonymization\n",
    "\n",
    "Medical data contains **Protected Health Information (PHI)** that must be removed for research use. This is required by HIPAA regulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244cc651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ingestion import Anonymizer\n",
    "\n",
    "# Initialize anonymizer with strict settings\n",
    "anonymizer = Anonymizer(\n",
    "    anonymization_level=\"strict\",  # Remove all PHI\n",
    "    date_shift_days=30  # Shift dates to preserve temporal relationships\n",
    ")\n",
    "\n",
    "print(\"Anonymizer Configuration:\")\n",
    "print(f\"  Level: {anonymizer.anonymization_level}\")\n",
    "print(f\"  Date shift: {anonymizer.date_shift_days} days\")\n",
    "print(f\"  PHI tags tracked: {len(anonymizer.PHI_TAGS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89cd2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate patient ID hashing\n",
    "print(\"Patient ID Anonymization (using secure hashing):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "test_patient_ids = [\"JOHN_DOE_123\", \"JANE_SMITH_456\", \"JOHN_DOE_123\"]  # Note duplicate\n",
    "\n",
    "for original_id in test_patient_ids:\n",
    "    anonymized_id = anonymizer.hash_patient_id(original_id)\n",
    "    print(f\"  {original_id:20} ‚Üí {anonymized_id}\")\n",
    "\n",
    "print(\"\\nüí° Notice: Same patient ID always produces the same hash!\")\n",
    "print(\"   This allows linking records while protecting identity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate date shifting\n",
    "print(\"Date Shifting (preserves temporal relationships):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "test_dates = [\"2024-01-15\", \"2024-01-20\", \"2024-02-01\"]\n",
    "\n",
    "print(f\"  Shift: +{anonymizer.date_shift_days} days\\n\")\n",
    "for date in test_dates:\n",
    "    shifted = anonymizer._shift_date_string(date)\n",
    "    print(f\"  {date} ‚Üí {shifted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3eb6f9",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. üñºÔ∏è Image Preprocessing\n",
    "\n",
    "Medical images need preprocessing before analysis:\n",
    "- **Windowing** - Adjusting contrast for visualization\n",
    "- **Resizing** - Standardizing dimensions\n",
    "- **Normalization** - Scaling pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35926706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import ImagePreprocessor\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = ImagePreprocessor(\n",
    "    target_size=(224, 224),  # Standard size for neural networks\n",
    "    normalize_method='zero_one',  # Scale to [0, 1]\n",
    "    augmentation=False,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(\"ImagePreprocessor Configuration:\")\n",
    "print(f\"  Target size: {preprocessor.target_size}\")\n",
    "print(f\"  Normalization: {preprocessor.normalize_method}\")\n",
    "print(f\"  Augmentation: {preprocessor.augmentation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1662076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic image to demonstrate preprocessing\n",
    "# (In real use, this would be loaded from a DICOM file)\n",
    "\n",
    "# Simulate a chest X-ray like image (512x512, 12-bit values)\n",
    "np.random.seed(42)\n",
    "synthetic_image = np.random.normal(1500, 500, (512, 512)).astype(np.float32)\n",
    "\n",
    "# Add some structure (simulate lung regions)\n",
    "y, x = np.ogrid[:512, :512]\n",
    "center_mask = ((x - 256)**2 + (y - 256)**2) < 200**2\n",
    "synthetic_image[center_mask] -= 800  # Lungs appear darker\n",
    "\n",
    "print(\"Synthetic Image Created:\")\n",
    "print(f\"  Shape: {synthetic_image.shape}\")\n",
    "print(f\"  Value range: [{synthetic_image.min():.0f}, {synthetic_image.max():.0f}]\")\n",
    "print(f\"  Dtype: {synthetic_image.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d95a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing steps\n",
    "print(\"Preprocessing Pipeline:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Step 1: Windowing\n",
    "windowed = preprocessor.apply_windowing(synthetic_image)\n",
    "print(f\"\\n1. Windowing:\")\n",
    "print(f\"   Input range: [{synthetic_image.min():.0f}, {synthetic_image.max():.0f}]\")\n",
    "print(f\"   Output range: [{windowed.min()}, {windowed.max()}]\")\n",
    "\n",
    "# Step 2: Resize\n",
    "resized = preprocessor.resize_image(windowed)\n",
    "print(f\"\\n2. Resizing:\")\n",
    "print(f\"   Input shape: {windowed.shape}\")\n",
    "print(f\"   Output shape: {resized.shape}\")\n",
    "\n",
    "# Step 3: Normalize\n",
    "normalized = preprocessor.normalize_image(resized)\n",
    "print(f\"\\n3. Normalization ({preprocessor.normalize_method}):\")\n",
    "print(f\"   Output range: [{normalized.min():.4f}, {normalized.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the preprocessing steps\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# Original\n",
    "axes[0].imshow(synthetic_image, cmap='gray')\n",
    "axes[0].set_title(f'Original\\n{synthetic_image.shape}')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Windowed\n",
    "axes[1].imshow(windowed, cmap='gray')\n",
    "axes[1].set_title(f'Windowed\\n[0-255]')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Resized\n",
    "axes[2].imshow(resized, cmap='gray')\n",
    "axes[2].set_title(f'Resized\\n{resized.shape}')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# Normalized\n",
    "axes[3].imshow(normalized, cmap='gray')\n",
    "axes[3].set_title(f'Normalized\\n[0-1]')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.suptitle('Image Preprocessing Pipeline', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e416df6",
   "metadata": {},
   "source": [
    "### Dataset Splitting\n",
    "\n",
    "For machine learning, we need to split data into train/validation/test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset\n",
    "n_samples = 100\n",
    "sample_paths = [f\"patient_{i:03d}/image.dcm\" for i in range(n_samples)]\n",
    "sample_labels = [0] * 60 + [1] * 40  # 60% class 0, 40% class 1\n",
    "\n",
    "# Split the dataset\n",
    "splits = preprocessor.create_dataset_split(\n",
    "    sample_paths, \n",
    "    sample_labels,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    stratify=True  # Maintain class proportions\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Dataset Split Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "split_data = []\n",
    "for split_name, data in splits.items():\n",
    "    labels = data['labels']\n",
    "    total = len(labels)\n",
    "    class_0 = labels.count(0)\n",
    "    class_1 = labels.count(1)\n",
    "    split_data.append({\n",
    "        'Split': split_name.capitalize(),\n",
    "        'Total': total,\n",
    "        'Class 0': class_0,\n",
    "        'Class 1': class_1,\n",
    "        'Class 0 %': f\"{class_0/total*100:.1f}%\",\n",
    "        'Class 1 %': f\"{class_1/total*100:.1f}%\"\n",
    "    })\n",
    "\n",
    "split_df = pd.DataFrame(split_data)\n",
    "print(split_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° Note: Stratification ensures each split has similar class proportions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1883e939",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. üß™ Blood Test Data Processing\n",
    "\n",
    "Clinical lab data provides important context for medical imaging analysis. Let's use **pandas** to process blood test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a17ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ingestion import BloodTestLoader\n",
    "from ingestion.blood_test_loader import REFERENCE_RANGES\n",
    "\n",
    "# Initialize the loader\n",
    "lab_loader = BloodTestLoader(\n",
    "    normalize_units=True,\n",
    "    add_reference_ranges=True,\n",
    "    validate_values=True\n",
    ")\n",
    "\n",
    "print(\"BloodTestLoader Configuration:\")\n",
    "print(f\"  Normalize units: {lab_loader.normalize_units}\")\n",
    "print(f\"  Add reference ranges: {lab_loader.add_reference_ranges}\")\n",
    "print(f\"  Validate values: {lab_loader.validate_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display reference ranges for common tests\n",
    "print(\"Reference Ranges for Common Blood Tests:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "ref_data = []\n",
    "for test_name, values in list(REFERENCE_RANGES.items())[:10]:\n",
    "    ref_data.append({\n",
    "        'Test': test_name,\n",
    "        'Min': values['min'],\n",
    "        'Max': values['max'],\n",
    "        'Unit': values['unit']\n",
    "    })\n",
    "\n",
    "ref_df = pd.DataFrame(ref_data)\n",
    "print(ref_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d48e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample blood test data (simulating hospital lab results)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate realistic lab data for multiple patients\n",
    "patients = ['P001', 'P002', 'P003', 'P004', 'P005']\n",
    "tests = ['WBC', 'Hemoglobin', 'Glucose', 'Creatinine', 'CRP']\n",
    "\n",
    "lab_records = []\n",
    "for patient in patients:\n",
    "    for test in tests:\n",
    "        ref = REFERENCE_RANGES[test]\n",
    "        # Generate values (some normal, some abnormal)\n",
    "        if np.random.random() < 0.7:  # 70% normal\n",
    "            value = np.random.uniform(ref['min'], ref['max'])\n",
    "        else:  # 30% abnormal\n",
    "            if np.random.random() < 0.5:\n",
    "                value = ref['min'] * np.random.uniform(0.5, 0.9)  # Low\n",
    "            else:\n",
    "                value = ref['max'] * np.random.uniform(1.1, 1.5)  # High\n",
    "        \n",
    "        lab_records.append({\n",
    "            'patient_id': patient,\n",
    "            'lab_name': test,\n",
    "            'value': round(value, 2),\n",
    "            'unit': ref['unit'],\n",
    "            'test_datetime': pd.Timestamp('2024-01-15') + pd.Timedelta(days=np.random.randint(0, 30))\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "lab_df = pd.DataFrame(lab_records)\n",
    "print(f\"Created sample lab data: {len(lab_df)} records\")\n",
    "print(f\"\\nFirst 10 records:\")\n",
    "lab_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the lab data\n",
    "processed_labs = lab_loader.load_dataframe(lab_df)\n",
    "\n",
    "print(\"Processed Lab Data:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show with validation results\n",
    "display_cols = ['patient_id', 'lab_name', 'value', 'ref_min', 'ref_max', 'abnormal_flag']\n",
    "processed_labs[display_cols].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results\n",
    "print(\"Lab Value Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Count by abnormal flag\n",
    "flag_counts = processed_labs['abnormal_flag'].value_counts()\n",
    "print(\"\\nValue Distribution:\")\n",
    "for flag, count in flag_counts.items():\n",
    "    pct = count / len(processed_labs) * 100\n",
    "    bar = '‚ñà' * int(pct / 2)\n",
    "    print(f\"  {flag:8} : {count:3} ({pct:5.1f}%) {bar}\")\n",
    "\n",
    "# Patients with abnormal values\n",
    "print(\"\\nPatients with Abnormal Values:\")\n",
    "abnormal = processed_labs[processed_labs['is_abnormal'] == True]\n",
    "patient_abnormal = abnormal.groupby('patient_id')['lab_name'].apply(list)\n",
    "for patient, tests in patient_abnormal.items():\n",
    "    print(f\"  {patient}: {', '.join(tests)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f30630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize lab results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Value distribution by test\n",
    "sns.boxplot(data=processed_labs, x='lab_name', y='value', ax=axes[0])\n",
    "axes[0].set_title('Lab Value Distribution by Test', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Test Name')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Abnormal flag distribution\n",
    "flag_counts.plot(kind='pie', autopct='%1.1f%%', ax=axes[1], \n",
    "                 colors=['#2ecc71', '#e74c3c', '#f39c12'])\n",
    "axes[1].set_title('Abnormal Value Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f7d8b6",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. üìä Visualization\n",
    "\n",
    "The visualization module creates charts and reports for analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f46e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import ResultsVisualizer\n",
    "\n",
    "# Initialize visualizer\n",
    "visualizer = ResultsVisualizer(\n",
    "    figure_size=(12, 8),\n",
    "    style='seaborn-v0_8-darkgrid',\n",
    "    color_palette='Set2'\n",
    ")\n",
    "\n",
    "print(\"ResultsVisualizer initialized!\")\n",
    "print(f\"  Figure size: {visualizer.figure_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cccc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample prediction data (simulating model outputs)\n",
    "np.random.seed(42)\n",
    "\n",
    "sample_predictions = []\n",
    "classes = ['Normal', 'Pneumonia', 'CHF']\n",
    "class_weights = [0.5, 0.35, 0.15]  # Class distribution\n",
    "\n",
    "for i in range(50):\n",
    "    pred_class = np.random.choice(classes, p=class_weights)\n",
    "    # Higher confidence for Normal, lower for others\n",
    "    if pred_class == 'Normal':\n",
    "        confidence = np.random.uniform(0.75, 0.98)\n",
    "    else:\n",
    "        confidence = np.random.uniform(0.55, 0.90)\n",
    "    \n",
    "    sample_predictions.append({\n",
    "        'prediction': pred_class,\n",
    "        'confidence': confidence,\n",
    "        'study_date': (pd.Timestamp('2024-01-01') + pd.Timedelta(days=i*3)).strftime('%Y-%m-%d')\n",
    "    })\n",
    "\n",
    "print(f\"Created {len(sample_predictions)} sample predictions\")\n",
    "pd.DataFrame(sample_predictions).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8671a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction distribution\n",
    "fig = visualizer.plot_prediction_distribution(\n",
    "    sample_predictions,\n",
    "    show_plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6dc69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confidence distribution by class\n",
    "fig = visualizer.plot_confidence_distribution(\n",
    "    sample_predictions,\n",
    "    by_class=True,\n",
    "    show_plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample patient report\n",
    "patient_report = {\n",
    "    'patient_id': 'ANON_A1B2C3D4E5F6',\n",
    "    'predictions': sample_predictions[:5],\n",
    "    'summary': {\n",
    "        'num_images': 5,\n",
    "        'num_predictions': 5,\n",
    "        'num_lab_tests': 10,\n",
    "        'num_correlations': 3\n",
    "    },\n",
    "    'correlations': []\n",
    "}\n",
    "\n",
    "# Plot patient timeline\n",
    "fig = visualizer.plot_patient_timeline(\n",
    "    patient_report,\n",
    "    show_plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5032497",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated the core functionality of the Medical Imaging DICOM Processing Pipeline:\n",
    "\n",
    "| Module | Purpose | Key Libraries |\n",
    "|--------|---------|---------------|\n",
    "| **Ingestion** | Load DICOM files, validate format | pydicom |\n",
    "| **Anonymization** | Remove PHI, hash patient IDs | hashlib |\n",
    "| **Preprocessing** | Resize, normalize, augment images | numpy, PIL |\n",
    "| **Blood Tests** | Load and validate lab data | pandas |\n",
    "| **Visualization** | Create charts and reports | matplotlib, seaborn |\n",
    "\n",
    "### Python Concepts Demonstrated\n",
    "\n",
    "- ‚úÖ Object-Oriented Programming (classes, methods, encapsulation)\n",
    "- ‚úÖ NumPy array operations\n",
    "- ‚úÖ Pandas DataFrames for data manipulation\n",
    "- ‚úÖ Type hints and docstrings\n",
    "- ‚úÖ File I/O and path handling\n",
    "- ‚úÖ Matplotlib/Seaborn visualization\n",
    "- ‚úÖ Configuration management\n",
    "- ‚úÖ Logging\n",
    "\n",
    "---\n",
    "*Medical Imaging DICOM Processing Pipeline - Course Submission*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
